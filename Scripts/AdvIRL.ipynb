{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msgpack\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from scenes import *\n",
    "import pyngp as ngp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene(scene):\n",
    "\tfor scenes in [scenes_sdf, scenes_nerf, scenes_image, scenes_volume]:\n",
    "\t\tif scene in scenes:\n",
    "\t\t\treturn scenes[scene]\n",
    "\treturn None\n",
    "\n",
    "def Train_NeRF(testbed, load_snapshot, screenshot_transforms, screenshot_dir, sharpen=0, exposure=0.0, screenshot_frames=None, screenshot_spp=16, width=224, height=224, network=None):\n",
    "\n",
    "\tif load_snapshot:\n",
    "\t\tscene_info = get_scene(load_snapshot)\n",
    "\t\tif scene_info is not None:\n",
    "\t\t\tload_snapshot = default_snapshot_filename(scene_info)\n",
    "\t\ttestbed.load_snapshot(load_snapshot)\n",
    "\n",
    "\tref_transforms = {}\n",
    "\tif screenshot_transforms: # try to load the given file straight away\n",
    "\t\tprint(\"Screenshot transforms from \", screenshot_transforms)\n",
    "\t\twith open(screenshot_transforms) as f:\n",
    "\t\t\tref_transforms = json.load(f)\n",
    "\n",
    "\tif testbed.mode == ngp.TestbedMode.Sdf:\n",
    "\t\ttestbed.tonemap_curve = ngp.TonemapCurve.ACES\n",
    "\n",
    "\ttestbed.nerf.sharpen = float(sharpen)\n",
    "\ttestbed.exposure = exposure\n",
    "\ttestbed.shall_train = True\n",
    "\n",
    "\n",
    "\ttestbed.nerf.render_with_lens_distortion = True\n",
    "\n",
    "\tif ref_transforms:\n",
    "\t\ttestbed.fov_axis = 0\n",
    "\t\ttestbed.fov = ref_transforms[\"camera_angle_x\"] * 180 / np.pi\n",
    "\t\tif not screenshot_frames:\n",
    "\t\t\tscreenshot_frames = range(len(ref_transforms[\"frames\"]))\n",
    "\n",
    "\t\tfor idx in screenshot_frames:\n",
    "\t\t\tf = ref_transforms[\"frames\"][int(idx)]\n",
    "\t\t\tif 'transform_matrix' in f:\n",
    "\t\t\t\tcam_matrix = f['transform_matrix']\n",
    "\t\t\telif 'transform_matrix_start' in f:\n",
    "\t\t\t\tcam_matrix = f[\"transform_matrix_start\"]\n",
    "\t\t\telse:\n",
    "\t\t\t\traise KeyError()\n",
    "\t\t\ttestbed.set_nerf_camera_matrix(np.matrix(cam_matrix)[:-1,:])\n",
    "\t\t\toutname = os.path.join(screenshot_dir, os.path.basename(f[\"file_path\"]))\n",
    "\n",
    "\t\t\t# Some NeRF datasets lack the .png suffix in the dataset metadata\n",
    "\t\t\tif not os.path.splitext(outname)[1]:\n",
    "\t\t\t\toutname = outname + \".png\"\n",
    "\n",
    "\t\t\timage = testbed.render(width or int(ref_transforms[\"w\"]), height or int(ref_transforms[\"h\"]), screenshot_spp, True)\n",
    "\t\t\tos.makedirs(os.path.dirname(outname), exist_ok=True)\n",
    "\t\t\twrite_image(outname, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNeRFData(fileName = \"../SavedModel.msgpack\"):\n",
    "    with open(fileName, \"rb\") as data_file:\n",
    "        byte_data = data_file.read()\n",
    "        data_loaded = msgpack.unpackb(byte_data)\n",
    "        parameters = np.frombuffer(data_loaded[\"snapshot\"][\"params_binary\"], dtype=np.float16).copy()\n",
    "        return data_loaded, parameters\n",
    "        \n",
    "def SaveParameters(data_loaded, parameters, outputFileName = \"../Test.msgpack\"):\n",
    "    data_loaded['snapshot']['params_binary'] = parameters.tobytes()\n",
    "\n",
    "    with open(outputFileName, \"wb\") as file:\n",
    "        file.write(msgpack.packb(data_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2()\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# from gymnasium import spaces\n",
    "# import numpy as np\n",
    "# from stable_baselines3 import PPO, A2C\n",
    "# from stable_baselines3.common.env_checker import check_env\n",
    "# from PIL import Image\n",
    "# from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "\n",
    "# # Preprocess numpy images\n",
    "# def preprocess(image, unproc=False):\n",
    "#     if not unproc:\n",
    "#         image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "#         return np.asarray(image, dtype=np.float32)\n",
    "#     else:\n",
    "#         return np.asarray(image, dtype=np.uint8)\n",
    "#     # Iteration ste\n",
    "\n",
    "# # Loads images from path\n",
    "# def prep_im(image_path, unproc=False):\n",
    "#     image = np.asarray(Image.open(image_path), dtype=np.float32)\n",
    "#     # ## print(image_raw.shape())\n",
    "#     image = image[None, ...]\n",
    "#     image = preprocess(image, unproc=unproc)\n",
    "#     #     image_probs = pretrained_model.predict(image)\n",
    "#     #     plot_fig(image, image_probs)\n",
    "#     return image\n",
    "\n",
    "# pred = pretrained_model.predict(prep_im(\"../../Slug69Percent.jpg\"))\n",
    "# decode_predictions(pred, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbed = ngp.Testbed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "logPath = '../AdvOutput/rewards.log'\n",
    "# Preprocess numpy images\n",
    "def preprocess(image, unproc=False):\n",
    "    if not unproc:\n",
    "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "        return np.asarray(image, dtype=np.float32)\n",
    "    else:\n",
    "        return np.asarray(image, dtype=np.uint8)\n",
    "    # Iteration ste\n",
    "\n",
    "# Loads images from path\n",
    "def prep_im(image_path, unproc=False):\n",
    "    image = np.asarray(Image.open(image_path), dtype=np.float32)\n",
    "    # ## print(image_raw.shape())\n",
    "    image = image[None, ...]\n",
    "    image = preprocess(image, unproc=unproc)\n",
    "    #     image_probs = pretrained_model.predict(image)\n",
    "    #     plot_fig(image, image_probs)\n",
    "    return image\n",
    "\n",
    "class InstantNGPEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(InstantNGPEnv, self).__init__()\n",
    "        # self.reward_range = (-1,1)\n",
    "        # Load Instant-NGP and MobileNetV2 models\n",
    "        # self.instant_ngp = ...  # Load Instant-NGP model\n",
    "        self.data_loaded, self.feature_grid = loadNeRFData()\n",
    "        self.ground_truth_img = None\n",
    "        self.log = open(logPath, 'a')\n",
    "\n",
    "\n",
    "        self.mobilenetv2 = pretrained_model  # Load MobileNetV2 model\n",
    "        self.true_class_id = 954\n",
    "        self.true_class = \"banana\"\n",
    "        self.target = \"slug\" # Target tiger shark class\n",
    "        self.noiseAmount = 0.15\n",
    "        self.max_reward = -np.inf\n",
    "        self.epochs = 0\n",
    "        self.targeted_grad = None\n",
    "        self.unrendered = None\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        self.Num_Imgs = 172\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(low=-0.005, high=0.005, shape=(13205056,), dtype=np.float32)  # Define space of allowable feature grid modifications\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(13205056,), dtype=np.float32) # Define state representation (e.g., feature grid, image)\n",
    "\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        super().reset(seed=seed)\n",
    "        # Reset feature grid or load new one\n",
    "        self.mobilenetv2.trainable = False\n",
    "        self.ground_truth_img = prep_im(\"../NormalOutput/0081.jpg\")\n",
    "        self.data_loaded, self.feature_grid = loadNeRFData()\n",
    "        # self.log.close()\n",
    "        return (self.feature_grid, {})\n",
    "    \n",
    "    def get_reward(self, originalImage, renderedImage, predicted, min_psnr=30, max_psnr=50, mse_weight = -2, psnr_weight = .5):\n",
    "\n",
    "        returned_reward = 0\n",
    "        imageLoss = mse(originalImage, renderedImage)\n",
    "        psnr = (peak_signal_noise_ratio(originalImage, renderedImage, data_range=255) - min_psnr) / (max_psnr - min_psnr)\n",
    "        if predicted[1] == self.target:\n",
    "            returned_reward = predicted[2] * 10 + predicted[0]*.2 # psnr * psnr_weight + imageLoss * mse_weight # TODO: Commented out to test and see if it increases accuracy\n",
    "        elif predicted[1] != self.true_class and predicted[0] == self.Num_Imgs:\n",
    "            returned_reward += predicted[2] * 10 + predicted[0] * .2\n",
    "        else:\n",
    "            returned_reward = -100\n",
    "\n",
    "        print(\"Psnr: \" + str(psnr) + \", MSE: \" + str(imageLoss) + \" for class \" + predicted[1])\n",
    "        return returned_reward\n",
    "\n",
    "    def step(self, action):\n",
    "        # Modify feature grid based on action\n",
    "        self.feature_grid +=  action[0] * self.noiseAmount  # Apply action to feature grid\n",
    "\n",
    "        # Render image from modified feature grid\n",
    "        SaveParameters(self.data_loaded, self.feature_grid)\n",
    "        Train_NeRF(testbed, \"../Test.msgpack\", \"../BananaScene/transforms.json\", \"../AdvOutput/\")\n",
    "\n",
    "        # TODO: Modify code to iterate through a range of image, test images on ImageNetV2, and find the common predictions between all of them.\n",
    "        # TODO: use common label as the true label predicted.\n",
    "        pred_classes = {}\n",
    "        for i in range(1, self.Num_Imgs):\n",
    "            image = prep_im(f\"../AdvOutput/{i:04}.jpg\")\n",
    "            # Classify image using MobileNetV2\n",
    "            prediction = self.mobilenetv2.predict(image, verbose=0)\n",
    "\n",
    "            # print(\"Top prediction:  \" + str(decode_predictions(prediction, top=1)))\n",
    "\n",
    "            decoded_prediction = decode_predictions(prediction, top=1)[0][0]\n",
    "\n",
    "            if decoded_prediction[1] not in pred_classes:\n",
    "                pred_classes[decoded_prediction[1]] = [decoded_prediction[2], 1]\n",
    "            else:\n",
    "                pred_classes[decoded_prediction[1]][0] *= pred_classes[decoded_prediction[1]][1]\n",
    "                pred_classes[decoded_prediction[1]][0] += decoded_prediction[2]\n",
    "                pred_classes[decoded_prediction[1]][1] += 1\n",
    "                pred_classes[decoded_prediction[1]][0] /= pred_classes[decoded_prediction[1]][1]\n",
    "        maxKey = str(max(pred_classes, key=lambda x:pred_classes[x][1]))\n",
    "        print(\"Max Key Found: \" + maxKey + \" with \" + str(pred_classes[maxKey][1]) + \" number of images with this label\")\n",
    "        print(\"dictionary: \" + str(pred_classes))\n",
    "        print(\"pred: \" + maxKey + \", confidence: \" + str(pred_classes[maxKey][0]))\n",
    "        # print(\"true pred: \" + self.true_class + \", confidence: \" + str(avg_true_confidence))\n",
    "        # Calculate reward based on adversarial success and image quality\n",
    "        reward = self.get_reward(self.ground_truth_img, image, [pred_classes[maxKey][1], maxKey, pred_classes[maxKey][0]])  # Implement reward function\n",
    "        # reward += (1 - (np.squeeze(prediction)[self.true_class_id])) # TODO: Adjust reward so model gets to slug with high accuracy.\n",
    "        reward -= 0 if self.true_class not in pred_classes else pred_classes[self.true_class][0]*10\n",
    "        # print(\"Banana: \" + str(decode_predictions(prediction)) + \", conf: \" + str(np.squeeze(prediction)[self.true_class_id]))\n",
    "        # Determine if episode is done\n",
    "        done = False\n",
    "\n",
    "        # done = True if reward <= -100 else False  # Define termination criteria\n",
    "        truncated, info = False, {}\n",
    "        \n",
    "        if self.epochs % 10 == 0 or reward == self.max_reward:\n",
    "        # if self.epochs % 250 == 0:\n",
    "            print('saving tape...')\n",
    "            self.log.write(\n",
    "                '\\n'\n",
    "                + str(self.epochs)\n",
    "                + ', '\n",
    "                + str(decode_predictions(prediction, top=1))\n",
    "            )\n",
    "        self.epochs += 1\n",
    "\n",
    "        info = {\n",
    "            \"Target\" : self.target,\n",
    "            \"Predicted\" : maxKey,\n",
    "            \"Num_Imgs\" : pred_classes[maxKey][1],\n",
    "            \"Confidence\" : pred_classes[maxKey][0],\n",
    "            \"Epochs\" : self.epochs\n",
    "        }\n",
    "\n",
    "        return self.feature_grid, reward, done, truncated, info\n",
    "\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        self.log.close()\n",
    "\n",
    "# Create environment instance\n",
    "env = InstantNGPEnv()\n",
    "\n",
    "# Create RL agent\n",
    "model = PPO('MlpPolicy', env, device='cuda')\n",
    "\n",
    "# Train the agent\n",
    "# Evaluate the trained agent\n",
    "episode_reward = 0\n",
    "obs, info = env.reset()\n",
    "_states = None\n",
    "\n",
    "epochs = 0\n",
    "while True:\n",
    "    action, _states = model.predict(obs, _states)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    print(\"Current episode reward: \" + str(episode_reward))\n",
    "\n",
    "    # TODO: Why did this throw an error? \"Target\" is a defined key in the info dictionary. Literally right there.\n",
    "    if (info['Target'] == info['Predicted'] and info['Confidence'] >= .65 and info[\"Num_Imgs\"] >= 172):\n",
    "        print(\"Episode reward:\", episode_reward)\n",
    "        break\n",
    "\n",
    "    if epochs > 100 and info['Predicted'] != info['Target']:\n",
    "        obs, info = env.reset()\n",
    "        epochs = 0\n",
    "        episode_reward = 0\n",
    "        _states = None\n",
    "    elif info['Predicted'] == info[\"Target\"]:\n",
    "        epochs = 0\n",
    "    epochs += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python adversarialAttack.py --load_snapshot=../SavedModel.msgpack --screenshot_transforms=../BananaScene/transforms.json --screenshot_dir=../NormalOutput --width=224 --height=224\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained ImageNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InstantNGPENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
